import pandas as pd
import time
import sys
import os
import re
from datetime import datetime, timedelta, timezone
from curl_cffi import requests as cffi_requests # âœ¨ é—œéµï¼šä½¿ç”¨å½è£ç€è¦½å™¨è«‹æ±‚

# ä¿®æ­£ Windows è¼¸å‡ºç·¨ç¢¼
sys.stdout.reconfigure(encoding='utf-8')

# ==========================================
# ğŸ”‘ è¨­å®šå€
# ==========================================
CWA_API_KEY = os.getenv("CWA_API_KEY") 

# ==========================================
# ğŸ“ åœ°é»æ¸…å–® (å°æ‡‰ API ID)
# ==========================================
all_locations = {
    "F001": "å¤ªå¹³å±±æ£®æ—éŠæ¨‚å€", "F002": "å°é¢¨å£åœè»Šå ´", "F003": "é³¶å³°åœè»Šå ´",
    "F004": "å°å¤§æ¢…å³°å¯¦é©—è¾²å ´", "F005": "å¢¾ä¸è²“é¼»é ­", "F006": "å¢¾ä¸é¾ç£å…¬åœ’",
    "F007": "é«˜é›„æ¢…å±±é’å¹´æ´»å‹•ä¸­å¿ƒ", "F008": "è—¤ææ£®æ—éŠæ¨‚å€", "F009": "é«˜é›„éƒ½æœƒå…¬åœ’",
    "F010": "åŸºéš†å¤§æ­¦å´™ç ²å°åœè»Šå ´", "F011": "äº”åˆ†å±±", "F012": "çŸ³ç¢‡é›²æµ·åœ‹å°",
    "F013": "çƒä¾†é¢¨æ™¯ç‰¹å®šå€", "F014": "è§€éœ§æ£®æ—éŠæ¨‚å€", "F015": "é˜¿é‡Œå±±éŠæ¨‚å€",
    "F016": "æ–°ä¸­æ©«å¡”å¡”åŠ åœè»Šå ´", "F017": "é¹¿æ—å¤©æ–‡å°", "F018": "æ­¦é™µè¾²å ´",
    "F019": "å¤§é›ªå±±åœ‹å®¶æ£®æ—éŠæ¨‚å€", "F020": "ç¦å£½å±±è¾²å ´", "F021": "è‡ºä¸­éƒ½æœƒå…¬åœ’",
    "F022": "é™½æ˜å±±åœ‹å®¶å…¬åœ’å°æ²¹å‘åœè»Šå ´", "F023": "é™½æ˜å±±åœ‹å®¶å…¬åœ’æ“å¤©å´—",
    "F024": "ä¸ƒè‚¡æµ·å ¤", "F025": "å—ç€›å¤©æ–‡æ•™è‚²åœ’å€", "F026": "è‡ºå—éƒ½æœƒå…¬åœ’"
}

# ==========================================
# ğŸ› ï¸ æ ¸å¿ƒå‡½å¼ï¼šä½¿ç”¨ curl_cffi ä¸‹è¼‰ API (æŠ—å°é–ç‰ˆ)
# ==========================================
def fetch_file_api_data(data_id):
    """
    ä½¿ç”¨ curl_cffi æ¨¡æ“¬ Chrome ç€è¦½å™¨ä¸‹è¼‰æ°£è±¡ç½² APIï¼Œ
    å¾¹åº•è§£æ±º SSL æ†‘è­‰éŒ¯èª¤ (Missing Subject Key Identifier) èˆ‡ WAF é˜»æ“‹å•é¡Œã€‚
    """
    url = f"https://opendata.cwa.gov.tw/fileapi/v1/opendataapi/{data_id}"
    params = {"Authorization": CWA_API_KEY, "format": "JSON"}
    
    try:
        # âœ¨ é­”æ³•åœ¨é€™è£¡ï¼šimpersonate="chrome110"
        # é€™æœƒè®“ä½ çš„ç¨‹å¼ç¢¼åœ¨ç¶²è·¯ä¸Šçœ‹èµ·ä¾†åƒæ˜¯ä¸€å€‹çœŸå¯¦çš„ Chrome ç€è¦½å™¨
        response = cffi_requests.get(
            url, 
            params=params, 
            impersonate="chrome110", 
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ API ä¸‹è¼‰å¤±æ•— (Status {response.status_code}): {url}")
            return None
    except Exception as e:
        print(f"âŒ API é€£ç·šåš´é‡éŒ¯èª¤: {e}")
        return None

def find_location_data(json_data, target_pid):
    try:
        root = json_data.get('cwaopendata', {})
        dataset = root.get('Dataset', root.get('dataset', {}))
        locations_node = dataset.get('Locations', dataset.get('locations', {}))
        location_list = locations_node.get('Location', locations_node.get('location', []))

        for loc in location_list:
            current_pid = None
            param_set = loc.get('ParameterSet', loc.get('parameterSet', {}))
            params = param_set.get('Parameter', param_set.get('parameter', []))
            
            p_list = params if isinstance(params, list) else [params]
            for p in p_list:
                if p.get('ParameterName') == 'id':
                    current_pid = p.get('ParameterValue')
                    break
            
            if current_pid == target_pid:
                return loc
        return None
    except: return None

# ==========================================
# ğŸ’¾ CSV æ›´æ–°åŠŸèƒ½ (ä¿ç•™ä½ çš„æ­·å²è³‡æ–™éœ€æ±‚)
# ==========================================
def update_weekly_csv():
    # æŠ“å–ã€Œæœªä¾†ä¸€é€± (F-B0053-069)ã€è³‡æ–™
    data = fetch_file_api_data("F-B0053-069")
    if not data:
        print("âŒ ç„¡æ³•å–å¾—ä¸€é€±é å ±è³‡æ–™ï¼Œè·³é CSV æ›´æ–°ã€‚")
        return

    csv_data = []
    print(f"ğŸš€ æ­£åœ¨æ›´æ–° CSV è³‡æ–™åº«...")

    for pid, name in all_locations.items():
        loc = find_location_data(data, pid)
        if not loc: continue
        
        raw_elements = loc.get('WeatherElement', [])
        elements = {item.get('ElementName'): item.get('Time', []) for item in raw_elements}

        # F-B0053-069 æ¯ 12 å°æ™‚ä¸€ç­† (æ—©/æ™š)
        ref_time_list = elements.get('å¤©æ°£ç¾è±¡', [])
        
        for i, time_item in enumerate(ref_time_list):
            start_str = time_item.get('StartTime') 
            if not start_str: continue
            
            dt = datetime.fromisoformat(start_str)
            date_display = dt.strftime("%m/%d")
            time_label = "æ™šä¸Š" if dt.hour == 18 else "ç™½å¤©"

            try:
                wx = time_item['ElementValue']['Weather']
                
                # è¼”åŠ©å‡½å¼ï¼šå®‰å…¨å–å¾—æ•¸å€¼
                def get_val(key, idx):
                    lst = elements.get(key, [])
                    if idx < len(lst):
                        val_dict = lst[idx]['ElementValue']
                        return list(val_dict.values())[0] # å–ç¬¬ä¸€å€‹å€¼æœ€ä¿éšª
                    return "-"

                min_t = get_val('æœ€ä½æº«åº¦', i)
                max_t = get_val('æœ€é«˜æº«åº¦', i)
                min_at = get_val('æœ€ä½é«”æ„Ÿæº«åº¦', i)
                max_at = get_val('æœ€é«˜é«”æ„Ÿæº«åº¦', i)
                pop = get_val('12å°æ™‚é™é›¨æ©Ÿç‡', i)
                pop = f"{pop}%" if pop != " " else "0%"
                wind = get_val('è’²ç¦é¢¨ç´š', i)

                row = {
                    "location": name, "pid": pid, "date": date_display, "æ™‚é–“": time_label,
                    "å¤©æ°£ç‹€æ³": wx, "æœ€ä½æº«": min_t, "æœ€é«˜æº«": max_t,
                    "é«”æ„Ÿæœ€ä½æº«": min_at, "é«”æ„Ÿæœ€é«˜æº«": max_at,
                    "é™é›¨æ©Ÿç‡": pop, "è’²ç¦é¢¨ç´š": wind
                }
                csv_data.append(row)
            except: continue

    if csv_data:
        file_name = "all_taiwan_star_forecast.csv"
        df = pd.DataFrame(csv_data)
        df.to_csv(file_name, index=False, encoding="utf-8-sig")
        print(f"âœ… CSV æ›´æ–°æˆåŠŸï¼å·²å¯«å…¥ {len(df)} ç­†è³‡æ–™ã€‚")
    else:
        print("âš ï¸ é›–ç„¶æŠ“åˆ° API ä½†æ²’æœ‰è§£æå‡ºæœ‰æ•ˆè³‡æ–™ã€‚")

# ==========================================
# ğŸ”­ åŠŸèƒ½ Aï¼šä»Šæ™šè§€æ˜Ÿ (ä½¿ç”¨ F-B0053-071)
# ==========================================
def format_time_ranges(time_list):
    if not time_list: return ""
    hours = []
    for t in time_list:
        try: hours.append(int(t.split(':')[0]))
        except: continue
    if not hours: return ""

    has_evening = any(h >= 18 for h in hours)
    processed = [h + 24 if (h <= 5 and has_evening) else h for h in hours]
    processed.sort()
    
    ranges = []
    if not processed: return ""
    start_h = prev_h = processed[0]
    
    for i in range(1, len(processed)):
        curr = processed[i]
        if curr == prev_h + 1: prev_h = curr
        else:
            ranges.append(f"{start_h%24:02d}:00-{(prev_h+1)%24:02d}:00")
            start_h = prev_h = curr
    ranges.append(f"{start_h%24:02d}:00-{(prev_h+1)%24:02d}:00")
    return "ã€".join(ranges)

def get_impromptu_star_info(pid, location_name):
    # ä¸‹è¼‰ 3hr è³‡æ–™ (æŠ—å°é–)
    data = fetch_file_api_data("F-B0053-071") 
    if not data: return "âš ï¸ æ°£è±¡ç½²é€£ç·šå¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
    
    loc_data = find_location_data(data, pid)
    if not loc_data: return f"âŒ ç„¡è³‡æ–™: {location_name}"

    try:
        raw_elements = loc_data.get('WeatherElement', [])
        elements = {item.get('ElementName'): item.get('Time', []) for item in raw_elements}

        night_status = [] # (æ™‚é–“, å¤©æ°£)
        now = datetime.now(timezone.utc).astimezone(timezone(timedelta(hours=8)))
        
        weather_list = elements.get('å¤©æ°£ç¾è±¡', [])
        for i, item in enumerate(weather_list):
            t_str = item.get('DataTime') or item.get('StartTime')
            if not t_str: continue
            dt = datetime.fromisoformat(t_str)

            # ç¯©é¸æœªä¾†24hå…§çš„æ™šä¸Š
            if dt > now and (dt.hour >= 18 or dt.hour <= 5):
                if (dt - now).total_seconds() > 86400: continue
                
                wx = item['ElementValue']['Weather']
                night_status.append((dt.strftime('%H:%M'), wx))

        # è©•åˆ†èˆ‡å»ºè­°
        perfect_times = [t for t, w in night_status if "æ™´" in w]
        cloudy_times = [t for t, w in night_status if "å¤šé›²" in w and "æ™´" not in w]

        if perfect_times:
            return f"ğŸ”­ ã€{location_name}ã€‘è§€æ˜Ÿå»ºè­°ï¼šğŸ˜Š \nå¤ªæ£’äº†ï¼ä»Šæ™šæœ€é©åˆè§€æ˜Ÿçš„æ™‚æ®µç‚ºï¼š{format_time_ranges(perfect_times)}"
        elif cloudy_times:
            return f"ğŸ”­ ã€{location_name}ã€‘è§€æ˜Ÿå»ºè­°ï¼šğŸ˜ \nä»Šæ™šé›²é‡è¼ƒå¤šï¼Œè‹¥è¦ç¢°é‹æ°£å¯é¸é€™äº›æ™‚æ®µï¼š{format_time_ranges(cloudy_times)}"
        elif not night_status:
            return f"ğŸ”­ ã€{location_name}ã€‘\nç›®å‰æ°£è±¡ç½²è³‡æ–™æ›´æ–°ä¸­ï¼Œè«‹ç¨æ™šå†è©¦ã€‚"
        else:
            return f"ğŸ”­ ã€{location_name}ã€‘è§€æ˜Ÿå»ºè­°ï¼šğŸ˜­ \nä»Šæ™šå¤©æ°£ä¸ä½³ï¼ˆé™°å¤©æˆ–é›¨ï¼‰ï¼Œä¸å»ºè­°å‰å¾€è§€æ˜Ÿã€‚"

    except Exception as e: return f"âŒ è§£æéŒ¯èª¤: {e}"

# ==========================================
# ğŸ“… åŠŸèƒ½ Bï¼šæœªä¾†ä¸€é€± (è®€å– CSV)
# ==========================================
def get_weekly_star_info(location_name):
    file_name = "all_taiwan_star_forecast.csv"
    
    # æª”æ¡ˆä¸å­˜åœ¨æ™‚è‡ªå‹•æŠ“å– (ä¿®å¾© Render é‡å•Ÿå¾Œè³‡æ–™æ¶ˆå¤±å•é¡Œ)
    if not os.path.exists(file_name):
        update_weekly_csv()
    
    try:
        if not os.path.exists(file_name): return "âš ï¸ è³‡æ–™åº«æš«æ™‚ç„¡æ³•è®€å–ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        
        df = pd.read_csv(file_name, encoding="utf-8-sig")
        target_df = df[(df['location'].str.contains(location_name, na=False)) & (df['æ™‚é–“'] == "æ™šä¸Š")].copy()
        
        if target_df.empty: return f"æ‰¾ä¸åˆ°ã€Œ{location_name}ã€çš„è³‡æ–™ã€‚"

        today_str = datetime.now().strftime("%m/%d")
        
        data_list = target_df.head(7).to_dict('records')
        blocks = []
        for item in data_list:
            wx = str(item.get('å¤©æ°£ç‹€æ³', ''))
            
            # --- ä½ çš„è©•åˆ†é‚è¼¯ ---
            score = 1
            eval_msg = ""
            
            if "æ™´" in wx:
                score = 3
                try:
                    fl = float(str(item.get('é«”æ„Ÿæœ€ä½æº«', '20')).replace("..", ""))
                    if fl > 15: score += 1
                    if 20 <= fl <= 25: score += 1
                    
                    if fl < 15: eval_msg = "å¤©æ°£å¯’å†·ï¼Œå»ºè­°å¤šç©¿ä¿æš–è¡£ç‰©ï¼"
                    elif 15 <= fl < 20: eval_msg = "å¤©æ°£ç¨æ¶¼ï¼Œå»ºè­°ç©¿ä»¶è–„å¤–å¥—ï¼"
                    else: eval_msg = "é©åˆè§€æ˜Ÿçš„æº«ç†±å¤œæ™šï¼"
                except: eval_msg = "è«‹æ³¨æ„æ°£æº«è®ŠåŒ–ã€‚"
                
                try:
                    ws = item.get('è’²ç¦é¢¨ç´š', '0')
                    wm = re.findall(r'\d+', str(ws))
                    if wm and int(wm[-1]) >= 5: score -= 1
                except: pass

            elif "å¤šé›²" in wx:
                score = 2
                eval_msg = "é›²é‡è¼ƒå¤šï¼Œå¯ç¢°é‹æ°£ã€‚"
            else:
                score = 1
                eval_msg = "ä»Šæ™šä¸é©åˆè§€æ˜Ÿã€‚"

            score = max(1, min(5, score))
            stars = "â­" * score
            
            res = [
                f"ğŸ“… {item['date']} (æ™š)",
                f"å¤©æ°£: {wx}",
                f"æ°£æº«: {item['æœ€ä½æº«']}~{item['æœ€é«˜æº«']}Â°C",
                f"é™é›¨: {item['é™é›¨æ©Ÿç‡']}",
                f"æŒ‡æ•¸: {stars}",
                f"ğŸ“ {eval_msg}"
            ]
            blocks.append("\n".join(res))
            
        return f"ğŸŒŒ ã€{location_name}ã€‘æœªä¾†ä¸€é€±é å ±\n----------------------\n" + "\n\n".join(blocks)

    except Exception as e:
        return f"âŒ è®€å–è³‡æ–™å¤±æ•—ï¼Œæ­£åœ¨é‡æ–°æŠ“å–...({e})"

if __name__ == "__main__":
    if not CWA_API_KEY:
        print("âŒ è«‹å…ˆè¨­å®š CWA_API_KEY ç’°å¢ƒè®Šæ•¸ï¼")
    else:
        # æ¸¬è©¦ä¸€ä¸‹
        print("æ¸¬è©¦æ›´æ–° CSV...")
        update_weekly_csv()
        print("æ¸¬è©¦è®€å–...")
        print(get_weekly_star_info("é¹¿æ—å¤©æ–‡å°"))