name: Daily Star Forecast Crawl

on:
  schedule:
    # æ¯å¤©å°ç£æ™‚é–“ 00:00, 06:00, 12:00, 18:00 åŸ·è¡Œ
    # (å°æ‡‰ UTC æ™‚é–“ 16, 22, 04, 10)
    - cron: '0 16,22,4,10 * * *'
  workflow_dispatch: # è®“ä½ å¯ä»¥æ‰‹å‹•é»æ“ŠåŸ·è¡Œ

# --- ğŸ’¡ æ˜ç¢ºé–‹å•Ÿå¯«å…¥æ¬Šé™ (é€™æ¨£æ‰èƒ½ git push) ---
permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          # âœ¨ é—œéµä¿®æ­£ï¼šè£œä¸Š curl_cffi (è§£æ±ºå ±éŒ¯) å’Œ python-dotenv
          pip install requests pandas beautifulsoup4 lxml curl_cffi python-dotenv

      - name: Run scraper
        # âœ¨ é—œéµä¿®æ­£ï¼šæ³¨å…¥ API Key (è®“ç¨‹å¼è®€å¾—åˆ° Secrets)
        env:
          CWA_API_KEY: ${{ secrets.CWA_API_KEY }}
        run: python scraper_final.py

      - name: Commit and Push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add all_taiwan_star_forecast.csv
          # å¦‚æœè³‡æ–™æ²’è®Šå‹•ï¼Œcommit æœƒå¤±æ•—ï¼Œä½¿ç”¨ || exit 0 è®“æµç¨‹æ­£å¸¸çµæŸ
          git commit -m "Auto update forecast data" || exit 0
          git push