import requests
from bs4 import BeautifulSoup
import sys

# ä¿®æ­£ Windows è¼¸å‡ºç·¨ç¢¼
sys.stdout.reconfigure(encoding='utf-8')

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

def debug_scrape(pid):
    # é€™å°±æ˜¯ä½ æˆªåœ–ä¸­é¡¯ç¤ºçš„æ­£ç¢ºç¶²å€
    url = f"https://www.cwa.gov.tw/V8/C/L/StarView/MOD/Week/{pid}_Week_PC.html"
    print(f"ğŸš€ æ¸¬è©¦çˆ¬å–: {url}")
    
    try:
        response = requests.get(url, headers=headers)
        print(f"ğŸ“¡ HTTP ç‹€æ…‹ç¢¼: {response.status_code}") # é æœŸæ˜¯ 200
        
        response.encoding = 'utf-8'
        html_content = response.text
        
        # 1. æª¢æŸ¥ HTML æ˜¯å¦æœ‰å…§å®¹
        if not html_content.strip():
            print("âŒ è­¦å‘Šï¼šæŠ“åˆ°çš„ HTML æ˜¯ç©ºçš„ï¼")
            return

        # 2. å°å‡ºå‰ 500 å­—ä¾†æª¢æŸ¥
        print("\nğŸ“„ HTML å…§å®¹é è¦½ (å‰ 500 å­—):")
        print("-" * 50)
        print(html_content[:500])
        print("-" * 50)
        
        # 3. æª¢æŸ¥è¡¨æ ¼ ID æ˜¯å¦å­˜åœ¨
        soup = BeautifulSoup(html_content, "html.parser")
        table = soup.find("table") # å…ˆä¸æŒ‡å®š IDï¼ŒæŠ“æŠ“çœ‹æœ‰æ²’æœ‰ä»»ä½•è¡¨æ ¼
        
        if table:
            print(f"\nâœ… æˆåŠŸæ‰¾åˆ°ä¸€å€‹è¡¨æ ¼ï¼")
            print(f"ğŸ†” è¡¨æ ¼ ID æ˜¯: {table.get('id', 'æ²’æœ‰ ID')}") # çœ‹çœ‹å®ƒçš„ ID åˆ°åº•æ˜¯ä»€éº¼
            print(f"ğŸ“‹ Class æ˜¯: {table.get('class', 'æ²’æœ‰ Class')}")
        else:
            print("\nâŒ ç³Ÿç³•ï¼ŒBeautifulSoup èªªè£¡é¢å®Œå…¨æ²’æœ‰ <table> æ¨™ç±¤")

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- åŸ·è¡Œæ¸¬è©¦ ---
if __name__ == "__main__":
    debug_scrape("F022") # æ¸¬è©¦åˆæ­¡å±±