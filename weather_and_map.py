import pandas as pd
import sys
import os
import re
import requests # [æ–°å¢] ç”¨æ–¼å‘¼å« Google Maps API
from datetime import datetime, timedelta, timezone
from curl_cffi import requests as cffi_requests # âœ¨ é—œéµï¼šä½¿ç”¨å½è£ç€è¦½å™¨è«‹æ±‚
from dotenv import load_dotenv # [æ–°å¢] è®“é€™æ”¯ç¨‹å¼ä¹Ÿèƒ½è®€åˆ° .env

# ä¿®æ­£ Windows è¼¸å‡ºç·¨ç¢¼
sys.stdout.reconfigure(encoding='utf-8')

# ==========================================
# ğŸ”‘ è¨­å®šå€
# ==========================================
# [æ–°å¢] è¼‰å…¥ç’°å¢ƒè®Šæ•¸ (è§£æ±ºä½ å‰›å‰›å ±éŒ¯çš„å•é¡Œ)
load_dotenv()

CWA_API_KEY = os.getenv("CWA_API_KEY") 
GOOGLE_MAPS_KEY = os.getenv("GOOGLE_MAPS_KEY") # [æ–°å¢] Google API Key

# ==========================================
# ğŸ“ åœ°é»æ¸…å–® (å°æ‡‰ API ID)
# ==========================================
all_locations = {
    "F001": "å¤ªå¹³å±±æ£®æ—éŠæ¨‚å€", "F002": "å°é¢¨å£åœè»Šå ´", "F003": "é³¶å³°åœè»Šå ´",
    "F004": "å°å¤§æ¢…å³°å¯¦é©—è¾²å ´", "F005": "å¢¾ä¸è²“é¼»é ­", "F006": "å¢¾ä¸é¾ç£å…¬åœ’",
    "F007": "é«˜é›„æ¢…å±±é’å¹´æ´»å‹•ä¸­å¿ƒ", "F008": "è—¤ææ£®æ—éŠæ¨‚å€", "F009": "é«˜é›„éƒ½æœƒå…¬åœ’",
    "F010": "åŸºéš†å¤§æ­¦å´™ç ²å°åœè»Šå ´", "F011": "äº”åˆ†å±±", "F012": "çŸ³ç¢‡é›²æµ·åœ‹å°",
    "F013": "çƒä¾†é¢¨æ™¯ç‰¹å®šå€", "F014": "è§€éœ§æ£®æ—éŠæ¨‚å€", "F015": "é˜¿é‡Œå±±éŠæ¨‚å€",
    "F016": "æ–°ä¸­æ©«å¡”å¡”åŠ åœè»Šå ´", "F017": "é¹¿æ—å¤©æ–‡å°", "F018": "æ­¦é™µè¾²å ´",
    "F019": "å¤§é›ªå±±åœ‹å®¶æ£®æ—éŠæ¨‚å€", "F020": "ç¦å£½å±±è¾²å ´", "F021": "è‡ºä¸­éƒ½æœƒå…¬åœ’",
    "F022": "é™½æ˜å±±åœ‹å®¶å…¬åœ’å°æ²¹å‘åœè»Šå ´", "F023": "é™½æ˜å±±åœ‹å®¶å…¬åœ’æ“å¤©å´—",
    "F024": "ä¸ƒè‚¡æµ·å ¤", "F025": "å—ç€›å¤©æ–‡æ•™è‚²åœ’å€", "F026": "è‡ºå—éƒ½æœƒå…¬åœ’"
}

# [æ–°å¢] æ™¯é»åº§æ¨™è³‡æ–™åº« (API è¨ˆç®—å¿…é ˆè¦æœ‰ç²¾ç¢ºç¶“ç·¯åº¦)
# æ ¼å¼: "PID": (ç·¯åº¦, ç¶“åº¦)
LOCATION_COORDS = {
    "F001": (24.49305556, 121.536666), # å¤ªå¹³å±±
    "F002": (24.16222222, 121.288055), # å°é¢¨å£
    "F003": (24.11805556, 121.2372222), # é³¶å³°
    "F004": (24.0880555, 121.1744444), # å°å¤§æ¢…å³°
    "F005": (21.92166667, 120.7372222), # è²“é¼»é ­
    "F006": (21.92027778, 120.8527778), # é¾ç£å…¬åœ’
    "F007": (23.26527778, 120.8252778), # æ¢…å±±é’å¹´æ´»å‹•ä¸­å¿ƒ
    "F008": (23.0672222, 120.7555556), # è—¤æ
    "F009": (22.73305556, 120.3069444), # é«˜é›„éƒ½æœƒå…¬åœ’
    "F010": (25.15777778, 121.7097222), # å¤§æ­¦å´™ç ²å°
    "F011": (25.07047785, 121.781691), # äº”åˆ†å±±
    "F012": (24.95305556, 121.6366667), # çŸ³ç¢‡é›²æµ·åœ‹å°
    "F013": (24.84888889, 121.551666), # çƒä¾†
    "F014": (24.50666667, 121.1141667), # è§€éœ§
    "F015": (23.51305556, 120.8083333), # é˜¿é‡Œå±±
    "F016": (23.48722222, 120.889166), # å¡”å¡”åŠ 
    "F017": (23.46861111, 120.8736111), # é¹¿æ—å¤©æ–‡å°
    "F018": (24.35277778, 121.31), # æ­¦é™µè¾²å ´
    "F019": (24.27916667, 121.0258333), # å¤§é›ªå±±
    "F020": (24.24472222, 121.2452778), # ç¦å£½å±±
    "F021": (24.20666667, 120.5972222), # å°ä¸­éƒ½æœƒå…¬åœ’
    "F022": (25.1765691, 121.5488301), # å°æ²¹å‘
    "F023": (25.16666667, 121.5741667), # æ“å¤©å´—
    "F024": (23.10895896, 120.0596368), # ä¸ƒè‚¡æµ·å ¤
    "F025": (23.11916667, 120.3908333), # å—ç€›å¤©æ–‡é¤¨
    "F026": (22.93555556, 120.2252778)  # å°å—éƒ½æœƒå…¬åœ’
}

# ==========================================
# ğŸ› ï¸ æ ¸å¿ƒå‡½å¼ï¼šä½¿ç”¨ curl_cffi ä¸‹è¼‰ API (æŠ—å°é–ç‰ˆ)
# ==========================================
def fetch_file_api_data(data_id):
    """
    ä½¿ç”¨ curl_cffi æ¨¡æ“¬ Chrome ç€è¦½å™¨ä¸‹è¼‰æ°£è±¡ç½² APIï¼Œ
    å¾¹åº•è§£æ±º SSL æ†‘è­‰éŒ¯èª¤ (Missing Subject Key Identifier) èˆ‡ WAF é˜»æ“‹å•é¡Œã€‚
    """
    url = f"https://opendata.cwa.gov.tw/fileapi/v1/opendataapi/{data_id}"
    params = {"Authorization": CWA_API_KEY, "format": "JSON"} # ç”¨æˆ‘çš„æ†‘è­‰ä¸‹è¼‰jsnæª”
    
    try:
        # âœ¨ é­”æ³•åœ¨é€™è£¡ï¼šimpersonate="chrome110"
        # Google Chrome å¤§ç´„æ¯å€‹æœˆéƒ½æœƒæ›´æ–°ä¸€æ¬¡ç‰ˆæœ¬è™Ÿï¼ˆä¾‹å¦‚ Chrome 108, 109, 110... ç›´åˆ°ç¾åœ¨çš„ 120+ï¼‰ã€‚
        # chrome110 æ˜¯ curl_cffi å‡½å¼åº«ä¸­ä¸€å€‹éå¸¸ç©©å®šä¸”å…·å‚™ç¾ä»£å®‰å…¨ç‰¹å¾µï¼ˆå¦‚ HTTP/2ï¼‰çš„é è¨­å½è£ç›®æ¨™ã€‚
        response = cffi_requests.get(
            url, 
            params=params, # æŠŠåƒæ•¸è‡ªå‹•åŠ åœ¨url(ç¶²å€)å¾Œé¢
            impersonate="chrome110", 
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            # æˆåŠŸé€£ç·šä½†æ²’æ‹¿åˆ°è³‡æ–™(è¢«å°é–æˆ–æ˜¯æŸ¥ä¸åˆ°)
            print(f"âŒ API ä¸‹è¼‰å¤±æ•— (Status {response.status_code}): {url}")
            return None
    except Exception as e:
        # é€£ç·šå¤±æ•—
        print(f"âŒ API é€£ç·šåš´é‡éŒ¯èª¤: {e}")
        return None

def find_location_data(json_data, target_pid):
    try:
        root = json_data.get('cwaopendata', {})
        dataset = root.get('Dataset', root.get('dataset', {})) 
        locations_node = dataset.get('Locations', dataset.get('locations', {}))
        location_list = locations_node.get('Location', locations_node.get('location', [])) 
        # getåŒ…è‘—get:å…ˆåŸ·è¡Œå‰é¢ï¼Œç„¡è³‡æ–™å†åŸ·è¡Œå¾Œé¢ï¼Œä¾‹å¦‚å…ˆæ‰¾å¤§å°Dï¼Œå†æ‰¾å°å¯«dï¼Œå¦‚æœéƒ½æ²’æœ‰å°±å›å‚³è‡ªè¨‚çš„ç©ºçš„é è¨­å‹æ…‹(å­—å…¸æˆ–ä¸²åˆ—)ã€‚
        # æœ€å¾Œæ‰¾åˆ°åŒ…å«ä¸åŒåœ°é»(å­—å…¸å‹æ…‹)çš„è³‡è¨Šä¸¦åŒ…æˆä¸²åˆ—ã€‚

        for loc in location_list:
            current_pid = None
            param_set = loc.get('ParameterSet', loc.get('parameterSet', {}))
            params = param_set.get('Parameter', param_set.get('parameter', []))
            
            # æª¢æŸ¥ params æ˜¯ä¸æ˜¯æ¸…å–®ã€‚å¦‚æœæ˜¯ï¼Œå°±ç›´æ¥ç”¨ï¼›
            # å¦‚æœæ˜¯å­—å…¸æˆ–å…¶ä»–ï¼Œå°±æŠŠå®ƒåŒ…é€²ä¸­æ‹¬è™Ÿ [] è£¡ã€‚é€™æ¨£å¾Œé¢çš„ for p in p_list æ‰èƒ½çµ±ä¸€é‹ä½œã€‚
            p_list = params if isinstance(params, list) else [params]
            for p in p_list:
                if p.get('ParameterName') == 'id':
                    current_pid = p.get('ParameterValue')
                    break
            
            # target_pidæ˜¯å¾all_locations.items()å‡½å¼è·³è½‰éä¾†çš„ã€‚
            # all_locations.items()åŸ·è¡Œè¿´åœˆï¼Œå†å‘¼å«find_location_data()ã€‚
            if current_pid == target_pid:
                return loc
        return None
    except: return None

# [æ–°å¢] Google Maps Distance Matrix API å‘¼å«å‡½å¼
# [ä¿®æ”¹] å°‡åŸæœ¬çš„ get_real_walking_info æ”¹åä¸¦å‡ç´š
def get_route_info(origin_lat, origin_lng, dest_lat, dest_lng, mode="driving"):
    """
    mode åƒæ•¸æ”¯æ´: 
    - driving (é–‹è»Š)
    - walking (èµ°è·¯)
    - bicycling (è‡ªè¡Œè»Š/é¨è¡Œ)
    - transit (å¤§çœ¾é‹è¼¸ - éœ€ç‰¹å®šåŸå¸‚æ”¯æ´)
    """
    if not GOOGLE_MAPS_KEY:
        return None, None
        
    url = "https://maps.googleapis.com/maps/api/distancematrix/json"
    params = {
        "origins": f"{origin_lat},{origin_lng}",
        "destinations": f"{dest_lat},{dest_lng}",
        "mode": mode,  # é€™è£¡è®Šæˆè®Šæ•¸äº†
        "language": "zh-TW",
        "key": GOOGLE_MAPS_KEY
    }
    try:
        res = requests.get(url, params=params).json()
        if res['status'] == 'OK':
            element = res['rows'][0]['elements'][0]
            if element['status'] == 'OK':
                # å›å‚³: (è·é›¢, æ™‚é–“)
                return element['distance']['text'], element['duration']['text']
    except Exception as e:
        print(f"API Error ({mode}): {e}")
    return None, None

# ==========================================
# ğŸ’¾ CSV æ›´æ–°åŠŸèƒ½ (é›™æª”ç­–ç•¥: Botç”¨ / æ­·å²ç”¨)
# ==========================================
def update_weekly_csv():
    # æŠ“å–ã€Œæœªä¾†ä¸€é€± (F-B0053-069)ã€è³‡æ–™
    data = fetch_file_api_data("F-B0053-069")
    if not data:
        print("âŒ ç„¡æ³•å–å¾—ä¸€é€±é å ±è³‡æ–™ï¼Œè·³é CSV æ›´æ–°ã€‚")
        return

    csv_data = [] # æŠ“å–å®Œæˆä¸¦éœ€è¦å„²å­˜çš„è³‡æ–™
    print(f"ğŸš€ æ­£åœ¨æ›´æ–° CSV è³‡æ–™åº«...")

    for pid, name in all_locations.items():
        loc = find_location_data(data, pid)
        if not loc: continue
        
        raw_elements = loc.get('WeatherElement', [])
        elements = {item.get('ElementName'): item.get('Time', []) for item in raw_elements}

        # F-B0053-069 æ¯ 12 å°æ™‚ä¸€ç­† (æ—©/æ™š)
        ref_time_list = elements.get('å¤©æ°£ç¾è±¡', [])
        
        # ç”¨ enumerate è™•ç†ã€Œå¤šå€‹ä¸¦åˆ—æ¸…å–®ã€çš„åŒæ­¥å•é¡Œã€‚
        # ç•¶æˆ‘å€‘ç”¨ enumerate è·‘ã€Œå¤©æ°£ç¾è±¡ã€æ¸…å–®æ™‚ï¼Œæˆ‘å€‘æ‹¿åˆ°äº†ç·¨è™Ÿ iã€‚
        # é€™æ™‚æˆ‘å€‘å°±å¯ä»¥ç”¨åŒä¸€å€‹ç·¨è™Ÿ i å»ã€Œæœ€ä½æº«åº¦ã€æ¸…å–®è£¡æŠ“å‡ºå°æ‡‰çš„æº«åº¦ã€‚
        for i, time_item in enumerate(ref_time_list):
            start_str = time_item.get('StartTime') 
            if not start_str: continue
            
            # æŠŠå¤©æ°£ç¾è±¡çš„é–‹å§‹æ™‚é–“è½‰æ›æˆ"01/06"æ ¼å¼
            # å…ˆå»ºç«‹å¯¦ä¾‹å±¬æ€§ï¼Œå†é€éæ–¹æ³•è½‰æˆæ–°çš„æ ¼å¼
            # ä¸€é€±æ—¥å¤œè³‡æ–™æ˜¯ä»¥6åˆ°18æ™‚åšåˆ‡å‰²
            dt = datetime.fromisoformat(start_str)
            date_display = dt.strftime("%m/%d")
            time_label = "æ™šä¸Š" if dt.hour == 18 else "ç™½å¤©"

            try:
                # time_itemç¾åœ¨æ˜¯ä¸€å€‹å·¢ç‹€å­—å…¸ï¼Œå–å‡ºå¾Œï¼Œwxæ˜¯å¤©æ°£ç‹€æ³
                wx = time_item['ElementValue']['Weather']
                
                # è¼”åŠ©å‡½å¼ï¼šå®‰å…¨å–å¾—æ•¸å€¼
                def get_val(key, idx):
                    # å¾ elements å­—å…¸ï¼ˆè£¡é¢å­˜äº†æ‰€æœ‰å¤©æ°£å…ƒç´ ï¼‰ä¸­ï¼Œ
                    # æ ¹æ“š keyï¼ˆä¾‹å¦‚ï¼š'æœ€ä½æº«åº¦'ï¼‰æŠŠé‚£ä¸€é•·ä¸²çš„æ™‚é–“æ¸…å–®æ‹¿å‡ºä¾†ã€‚
                    lst = elements.get(key, [])
                    # ã€Œé‚Šç•Œæª¢æŸ¥ã€ã€‚è¬ä¸€ã€Œå¤©æ°£ç¾è±¡ã€æœ‰ 7 ç­†é å ±ï¼Œä½†ã€Œé™é›¨æ©Ÿç‡ã€åªæœ‰ 5 ç­†ï¼Œ
                    # å¦‚æœä¸æª¢æŸ¥ï¼Œç¨‹å¼è·‘åˆ°ç¬¬ 6 ç­†æ™‚å°±æœƒå› ç‚ºæ‰¾ä¸åˆ°è³‡æ–™è€Œç›´æ¥ç•¶æ©Ÿã€‚
                    # è§£æ³•ï¼šval_dict.values() æœƒæŠŠè£¡é¢æ‰€æœ‰çš„ã€Œå€¼ã€éƒ½æ‹¿å‡ºä¾†ï¼ˆä¸çœ‹ Keyï¼‰ï¼Œç„¶å¾Œè½‰æˆ list æ‹¿ç¬¬ä¸€å€‹ [0]ã€‚
                    # é€™æ¨£ä¸ç®¡æ˜¯å¤©æ°£é‚„æ˜¯æº«åº¦ï¼Œéƒ½èƒ½æ­£ç¢ºæŠ“åˆ°é‚£å€‹ã€Œæ•¸å€¼ã€ã€‚
                    if idx < len(lst):
                        val_dict = lst[idx]['ElementValue']
                        return list(val_dict.values())[0] # å–ç¬¬ä¸€å€‹å€¼æœ€ä¿éšª
                    return "-"

                min_t = get_val('æœ€ä½æº«åº¦', i)
                max_t = get_val('æœ€é«˜æº«åº¦', i)
                min_at = get_val('æœ€ä½é«”æ„Ÿæº«åº¦', i)
                max_at = get_val('æœ€é«˜é«”æ„Ÿæº«åº¦', i)
                pop = get_val('12å°æ™‚é™é›¨æ©Ÿç‡', i)
                pop = f"{pop}%" if pop != " " else "0%"
                wind = get_val('è’²ç¦é¢¨ç´š', i)

                row = {
                    "location": name, "pid": pid, "date": date_display, "æ™‚é–“": time_label,
                    "å¤©æ°£ç‹€æ³": wx, "æœ€ä½æº«": min_t, "æœ€é«˜æº«": max_t,
                    "é«”æ„Ÿæœ€ä½æº«": min_at, "é«”æ„Ÿæœ€é«˜æº«": max_at,
                    "é™é›¨æ©Ÿç‡": pop, "è’²ç¦é¢¨ç´š": wind
                }
                csv_data.append(row)
            except: continue

    # ==========================================
    # ğŸ‘‡ ä¿®æ”¹å€ï¼šè³‡æ–™åˆ†æµ (Botç”¨ vs æ­·å²ç”¨)
    # ==========================================
    if csv_data:
        # 1. æº–å‚™ç•¶ä¸‹çš„æ–°è³‡æ–™
        current_df = pd.DataFrame(csv_data)
        
        # -------------------------------------------------------
        # ğŸ“‚ æª”æ¡ˆ Aï¼šBot å°ˆç”¨ (æ¯æ¬¡è¦†è“‹ï¼Œåªç•™æœ€æ–° 7 å¤©ï¼Œé€Ÿåº¦å¿«)
        # -------------------------------------------------------
        bot_file = "all_taiwan_star_forecast.csv"
        current_df.to_csv(bot_file, index=False, encoding="utf-8-sig")
        print(f"âœ… Bot è³‡æ–™åº«å·²æ›´æ–° (è¦†è“‹æ¨¡å¼): å…± {len(current_df)} ç­†")

        # -------------------------------------------------------
        # ğŸ›ï¸ æª”æ¡ˆ Bï¼šæ­·å²å€‰åº« (ç´¯ç©æ¨¡å¼ï¼Œä¿ç•™éå»æ‰€æœ‰è³‡æ–™)
        # -------------------------------------------------------
        history_file = "history_repository.csv"
        
        if os.path.exists(history_file):
            try:
                old_df = pd.read_csv(history_file, encoding="utf-8-sig")
                # åˆä½µèˆŠè³‡æ–™ + æ–°è³‡æ–™
                history_df = pd.concat([old_df, current_df], ignore_index=True)
                # å»é™¤é‡è¤‡ï¼šå¦‚æœã€Œåœ°é»+æ™‚é–“ã€ä¸€æ¨£ï¼Œä¿ç•™æœ€æ–°çš„é å ± (keep='last')
                history_df.drop_duplicates(subset=['location', 'pid', 'date', 'æ™‚é–“'], keep='last', inplace=True)
            except:
                history_df = current_df # è®€å–å¤±æ•—å°±ç›´æ¥ç”¨æ–°çš„
        else:
            history_df = current_df # æ²’æª”æ¡ˆå°±ç›´æ¥å‰µæ–°çš„

        # [æ–°å¢] æ’åºåŠŸèƒ½ï¼šä¾ç…§ ID -> æ—¥æœŸ -> æ™‚é–“ æ’åˆ—ï¼Œè®“æ­·å²æª”æ•´é½Š
        if not history_df.empty:
            history_df.sort_values(by=['pid', 'date', 'æ™‚é–“'], inplace=True)

        history_df.to_csv(history_file, index=False, encoding="utf-8-sig")
        print(f"ğŸ“š æ­·å²è³‡æ–™åº«å·²å‚™ä»½ (ç´¯ç©+æ’åº): å…± {len(history_df)} ç­†")

    else:
        print("âš ï¸ é›–ç„¶æŠ“åˆ° API ä½†æ²’æœ‰è§£æå‡ºæœ‰æ•ˆè³‡æ–™ã€‚")
# ==========================================
# ğŸ”­ åŠŸèƒ½ Aï¼šä»Šæ™šè§€æ˜Ÿ (ä½¿ç”¨ F-B0053-071)
# ==========================================
def format_time_ranges(time_list):
    if not time_list: return ""
    hours = []
    for t in time_list:
        try: hours.append(int(t.split(':')[0]))
        except: continue
    if not hours: return ""

    # åˆ¤æ–·æ˜¯å¦æœ‰ã€Œæ™šä¸Šï¼ˆ18é»ä»¥å¾Œï¼‰ã€çš„è³‡æ–™
    has_evening = any(h >= 18 for h in hours)
    processed = [h + 24 if (h <= 5 and has_evening) else h for h in hours]
    processed.sort()
    
    ranges = []
    if not processed: return ""
    start_h = prev_h = processed[0]
    
    for i in range(1, len(processed)): # å¾ç¬¬2å€‹é–‹å§‹
        curr = processed[i]
        if curr == prev_h + 1: prev_h = curr
        else:
            ranges.append(f"{start_h%24:02d}:00-{(prev_h+1)%24:02d}:00")
            start_h = prev_h = curr
    ranges.append(f"{start_h%24:02d}:00-{(prev_h+1)%24:02d}:00")
    return "ã€".join(ranges)

def get_impromptu_star_info(pid, location_name):
    # å³æ™‚ä¸‹è¼‰ 3hr è³‡æ–™
    data = fetch_file_api_data("F-B0053-071") 
    if not data: return "âš ï¸ æ°£è±¡ç½²é€£ç·šå¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
    
    loc_data = find_location_data(data, pid)
    if not loc_data: return f"âŒ ç„¡è³‡æ–™: {location_name}"

    try:
        raw_elements = loc_data.get('WeatherElement', [])
        elements = {item.get('ElementName'): item.get('Time', []) for item in raw_elements}

        night_status = [] # (æ™‚é–“, å¤©æ°£)
        now = datetime.now(timezone.utc).astimezone(timezone(timedelta(hours=8)))
        
        weather_list = elements.get('å¤©æ°£ç¾è±¡', [])
        for i, item in enumerate(weather_list):
            # [ä¿®æ”¹ 1] åŒæ™‚å–å¾—é–‹å§‹èˆ‡çµæŸæ™‚é–“
            start_str = item.get('StartTime')
            end_str = item.get('EndTime')
            if not start_str or not end_str: continue
            
            start_dt = datetime.fromisoformat(start_str)
            end_dt = datetime.fromisoformat(end_str)
            wx = item['ElementValue']['Weather']

            # [ä¿®æ”¹ 2] å°‡ 3 å°æ™‚çš„æ™‚é–“å€æ®µï¼Œã€Œå±•é–‹ã€æˆæ¯å€‹å°æ™‚
            # ä¾‹å¦‚ 18:00~21:00 -> ç”¢ç”Ÿ 18:00, 19:00, 20:00 ä¸‰ç­†è³‡æ–™
            current_pointer = start_dt
            while current_pointer < end_dt:
                # åˆ¤æ–·æ˜¯å¦ç‚ºæ™šä¸Š (18~05) ä¸”æ˜¯æœªä¾†æ™‚é–“
                if current_pointer > now and (current_pointer.hour >= 18 or current_pointer.hour <= 5):
                    # æª¢æŸ¥æ˜¯å¦è¶…é 24 å°æ™‚ (é¿å…é¡¯ç¤ºå¤ªå¤šå¤©å¾Œçš„è³‡æ–™)
                    if (current_pointer - now).total_seconds() <= 86400:
                        night_status.append((current_pointer.strftime('%H:%M'), wx))
                
                # å¾€å¾Œæ¨ä¸€å°æ™‚
                current_pointer += timedelta(hours=1)

        # 1. æœ€å„ªå…ˆåˆ¤æ–·ï¼šæ˜¯å¦æœ‰å£å¤©æ°£ (é™°å¤©æˆ–é›¨)
        # åªè¦é€™æ®µæ™‚é–“å…§å‡ºç¾ä»»ä½• "é™°" æˆ– "é›¨" çš„å­—çœ¼ï¼Œå°±ç›´æ¥å‹¸é€€
        has_bad_weather = any("é™°" in w or "é›¨" in w for t, w in night_status)

        if has_bad_weather:
            return f"ğŸ”­ ã€{location_name}ã€‘è§€æ˜Ÿå»ºè­°ï¼šğŸ˜­ \nä»Šæ™šå¤©æ°£ä¸ä½³ï¼Œä¸å»ºè­°å‰å¾€è§€æ˜Ÿï¼Œè«‹å¥½å¥½ç¡è¦ºã€‚"

        # 2. å¦‚æœæ²’æœ‰å£å¤©æ°£ï¼Œæ‰é–‹å§‹æ‰¾å¥½å¤©æ°£
        perfect_times = [t for t, w in night_status if "æ™´" in w] # æŠ“"æ™´"ã€"æ™´æ™‚å¤šé›²"ã€"å¤šé›²æ™‚æ™´"ä¸‰ç¨®å¤©æ°£
        cloudy_times = [t for t, w in night_status if "å¤šé›²" in w and "æ™´" not in w]
        
        # å»é™¤é‡è¤‡ä¸¦ä¿æŒé †åº
        perfect_times = sorted(list(set(perfect_times)), key=lambda x: (int(x.split(':')[0]) + 24) if int(x.split(':')[0]) < 12 else int(x.split(':')[0]))
        cloudy_times = sorted(list(set(cloudy_times)), key=lambda x: (int(x.split(':')[0]) + 24) if int(x.split(':')[0]) < 12 else int(x.split(':')[0]))

        if perfect_times:
            return f"ğŸ”­ ã€{location_name}ã€‘è§€æ˜Ÿå»ºè­°ï¼šğŸ˜Š \nå¤ªæ£’äº†ï¼ä»Šæ™šæœ€é©åˆè§€æ˜Ÿçš„æ™‚æ®µç‚ºï¼š{format_time_ranges(perfect_times)}"
        elif cloudy_times:
            return f"ğŸ”­ ã€{location_name}ã€‘è§€æ˜Ÿå»ºè­°ï¼šğŸ˜ \nä»Šæ™šé›²é‡è¼ƒå¤šï¼Œå¯ç¢°é‹æ°£çš„æ™‚æ®µç‚ºï¼š{format_time_ranges(cloudy_times)}"
        elif not night_status:
            return f"ğŸ”­ ã€{location_name}ã€‘\nç›®å‰ä¸­å¤®æ°£è±¡ç½²è³‡æ–™æ›´æ–°ä¸­ï¼Œè«‹ç¨æ™šå†è©¦ã€‚"
        else:
            # é€™è£¡ç†è«–ä¸Šè·‘ä¸åˆ°äº†ï¼Œå› ç‚ºå£å¤©æ°£éƒ½è¢«ç¬¬ä¸€å€‹ if æŠ“èµ°äº†ï¼Œä½†ç•™è‘—ç•¶ä¿éšª
            return f"ğŸ”­ ã€{location_name}ã€‘è§€æ˜Ÿå»ºè­°ï¼šğŸ˜­ \nä»Šæ™šå¤©æ°£ä¸ä½³ï¼Œä¸å»ºè­°å‰å¾€è§€æ˜Ÿï¼Œè«‹å¥½å¥½ç¡è¦ºã€‚"

    except Exception as e: return f"âŒ è§£æéŒ¯èª¤: {e}"

# ==========================================
# ğŸ“… åŠŸèƒ½ Bï¼šæœªä¾†ä¸€é€± (Bot è®€å–å°ˆç”¨)
# ==========================================
def get_weekly_star_info(location_name):
    file_name = "all_taiwan_star_forecast.csv"
    
    # ==========================================
    # ğŸ•µï¸â€â™‚ï¸ æ™ºæ…§æª¢æŸ¥æ©Ÿåˆ¶ (é–‹å§‹)
    # ==========================================
    # 1. å–å¾—ã€Œå°ç£æ™‚é–“ã€ä»Šå¤©çš„æ—¥æœŸå­—ä¸² (æ ¼å¼å¿…é ˆè·Ÿ CSV è£¡çš„ "01/27" ä¸€æ¨¡ä¸€æ¨£)
    now_tw = datetime.now(timezone(timedelta(hours=8)))
    today_str = now_tw.strftime("%m/%d")
    
    need_update = False

    # 2. ç¬¬ä¸€é—œï¼šæª¢æŸ¥æª”æ¡ˆåœ¨ä¸åœ¨
    if not os.path.exists(file_name):
        print(f"âš ï¸ æ‰¾ä¸åˆ° {file_name}ï¼Œæº–å‚™ä¸‹è¼‰...")
        need_update = True
    else:
        # 3. ç¬¬äºŒé—œï¼šæª¢æŸ¥å…§å®¹æœ‰æ²’æœ‰éæœŸ
        try:
            # ç‚ºäº†çœè³‡æºï¼Œæˆ‘å€‘åªè®€å– 'date' é€™ä¸€æ¬„å°±å¥½
            df_check = pd.read_csv(file_name, usecols=['date'], encoding="utf-8-sig")
            
            # é‚è¼¯ï¼šå¦‚æœ CSV è£¡çš„æ‰€æœ‰æ—¥æœŸï¼Œå®Œå…¨æ‰¾ä¸åˆ°ã€Œä»Šå¤©ã€ï¼Œä»£è¡¨é€™ä»½è³‡æ–™æ˜¯èˆŠçš„
            # .values æ˜¯æŠŠæ¬„ä½è½‰æˆé™£åˆ—ï¼Œæ¯”è¼ƒé€Ÿåº¦å¿«
            if today_str not in df_check['date'].values:
                # ç‚ºäº† debug æ–¹ä¾¿ï¼Œå°å‡ºå®ƒæœ€æ–°çš„æ—¥æœŸæ˜¯å“ªä¸€å¤©
                last_date = df_check['date'].iloc[-1] if not df_check.empty else "ç©ºæª”æ¡ˆ"
                print(f"âš ï¸ è³‡æ–™åº«éæœŸ (æª”æ¡ˆæœ€æ–°æ—¥æœŸ: {last_date}ï¼Œä»Šå¤©æ˜¯: {today_str})ï¼Œå¼·åˆ¶æ›´æ–°...")
                need_update = True
            else:
                print("âœ… è³‡æ–™åº«æœ‰æ•ˆ (åŒ…å«ä»Šæ—¥è³‡æ–™)ï¼Œç›´æ¥è®€å–ã€‚")
                
        except Exception as e:
            print(f"âš ï¸ æª”æ¡ˆè®€å–ç•°å¸¸æˆ–æ ¼å¼éŒ¯èª¤ ({e})ï¼Œä¿éšªèµ·è¦‹å¼·åˆ¶é‡æŠ“...")
            need_update = True

    # 4. å¦‚æœä¸Šé¢çš„æª¢æŸ¥åˆ¤æ–·éœ€è¦æ›´æ–°ï¼Œå°±åœ¨é€™è£¡åŸ·è¡Œçˆ¬èŸ²
    if need_update:
        update_weekly_csv()
    # ==========================================
    # ğŸ•µï¸â€â™‚ï¸ æ™ºæ…§æª¢æŸ¥æ©Ÿåˆ¶ (çµæŸ)
    # ==========================================
    
    try:
        if not os.path.exists(file_name): return "âš ï¸ è³‡æ–™åº«æš«æ™‚ç„¡æ³•è®€å–ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        
        df = pd.read_csv(file_name, encoding="utf-8-sig")
        target_df = df[(df['location'].str.contains(location_name, na=False)) & (df['æ™‚é–“'] == "æ™šä¸Š")].copy()
        
        if target_df.empty: return f"æ‰¾ä¸åˆ°ã€Œ{location_name}ã€çš„è³‡æ–™ã€‚"

        # ç›´æ¥å–å‰ 7 ç­† (å› ç‚ºæª”æ¡ˆåªæœ‰æœ€æ–°çš„ï¼Œä¸ç”¨éæ¿¾æ—¥æœŸ)
        data_list = target_df.head(7).to_dict('records')
        blocks = []
        for item in data_list:
            wx = str(item.get('å¤©æ°£ç‹€æ³', ''))
            
            # --- è©•åˆ†é‚è¼¯ ---
            score = 1
            eval_msg = ""

            # 1. æœ€å„ªå…ˆæª¢æŸ¥ï¼šå£å¤©æ°£ (é™°å¤©æˆ–é›¨)
            # åªè¦å‡ºç¾é€™å…©å€‹å­—ï¼Œç›´æ¥åˆ¤å®šç‚ºä¸é©åˆï¼Œä¹Ÿä¸ç”¨ç®¡æº«åº¦äº†
            if "é™°" in wx or "é›¨" in wx:
                score = 1
                eval_msg = "ä»Šæ™šä¸é©åˆè§€æ˜Ÿã€‚"

            # 2. å¥½å¤©æ°£æª¢æŸ¥ï¼šæ™´å¤© æˆ– å¤šé›²
            elif "æ™´" in wx or "å¤šé›²" in wx:
                # --- A. æ±ºå®šåŸºç¤åˆ†æ•¸èˆ‡é–‹é ­èª ---
                if "æ™´" in wx:
                    score = 3
                    eval_msg = "ä»Šæ™šé«˜æ©Ÿç‡çœ‹åˆ°æ˜Ÿæ˜Ÿå“¦ï¼"
                else:
                    # é€™è£¡ä»£è¡¨åªæœ‰ã€Œå¤šé›²ã€(æ²’æœ‰æ™´ä¹Ÿæ²’æœ‰é›¨/é™°)
                    score = 2
                    eval_msg = "ä»Šæ™šé›²é‡è¼ƒå¤šï¼Œå¾ˆæƒ³çœ‹æ˜Ÿæ˜Ÿçš„è©±å¯ç¢°ç¢°é‹æ°£ã€‚"
                
                # --- B. æº«åº¦åˆ¤æ–· (æ™´å¤©è·Ÿå¤šé›²éƒ½ç”¨é€™ä¸€å¥—) ---
                try:
                    fl = float(str(item.get('é«”æ„Ÿæœ€ä½æº«', '20')).replace("..", ""))
                    
                    # æº«åº¦åŠ åˆ†é‚è¼¯
                    if fl > 15: score += 1
                    if 20 <= fl <= 25: score += 1
                    
                    # æº«åº¦å»ºè­°è¨Šæ¯ (è¨˜å¾—åŠ  \n æ›è¡Œ)
                    if fl < 15: eval_msg += "å¦ä»Šæ™šå¤©æ°£å¯’å†·ï¼Œå¤–å‡ºè§€æ˜Ÿå»ºè­°å¤šç©¿ä¿æš–è¡£ç‰©ï¼"
                    elif 15 <= fl < 20: eval_msg += "å¦ä»Šæ™šå¤©æ°£ç¨æ¶¼ï¼Œå¤–å‡ºè§€æ˜Ÿå»ºè­°ç©¿ä»¶è–„å¤–å¥—ï¼"
                    elif 20 <= fl <= 25: eval_msg += "å¦ä»Šæ™šå¤©æ°£èˆ’é©ï¼Œçµ•ä½³è§€æ˜Ÿæ—¥ï¼"
                    else: eval_msg += "å¦ä»Šæ™šæ˜¯é©åˆè§€æ˜Ÿçš„æº«ç†±å¤œæ™šï¼"
                except:
                    eval_msg += "\n(æº«åº¦è³‡æ–™æš«ç¼ºï¼Œè«‹æ³¨æ„æ°£æº«è®ŠåŒ–)"

                # --- C. é¢¨åŠ›æ‰£åˆ† (æ™´å¤©è·Ÿå¤šé›²éƒ½ç”¨é€™ä¸€å¥—) ---
                try:
                    ws = item.get('è’²ç¦é¢¨ç´š', '0')
                    wm = re.findall(r'\d+', str(ws))
                    if wm and int(wm[-1]) >= 5: score -= 1
                except: pass

            # 3. å…¶ä»–æœªçŸ¥å¤©æ°£
            else:
                score = 1
                eval_msg = "ä»Šæ™šä¸é©åˆè§€æ˜Ÿã€‚"

            # ç¢ºä¿åˆ†æ•¸åœ¨ 1~5 ä¹‹é–“
            score = max(1, min(5, score))
            stars = "â­" * score
            
            # ä¿®æ­£å¾Œçš„ f-string (è£œä¸Šäº†å¼•è™Ÿ)
            res = [
                f"ğŸ“… {item['date']} (æ™šä¸Š)",
                f"å¤©æ°£: {wx}",
                f"æ°£æº«: {item['æœ€ä½æº«']}~{item['æœ€é«˜æº«']}Â°C",
                f"é«”æ„Ÿ: {item.get('é«”æ„Ÿæœ€ä½æº«', '?')}~{item.get('é«”æ„Ÿæœ€é«˜æº«', '?')}Â°C",
                # f"é™é›¨: {item['é™é›¨æ©Ÿç‡']}",
                f"è§€æ˜Ÿæ¨è–¦æŒ‡æ•¸: {stars}",
                f"ğŸ“ç¶œåˆè©•ä¼°: {eval_msg}"
            ]
            blocks.append("\n".join(res))
            
        header = f"ğŸŒŒ ã€{location_name}ã€‘æœªä¾†ä¸€é€±è§€æ˜ŸæŒ‡å—\n"
        tail = "\n\n----------------\nğŸ”” æº«é¦¨æé†’ï¼šç•¶æ—¥å¯å†ç¢ºèªæ™´æœ—çš„æ™šé–“æ™‚æ®µå“¦ï¼"
        return header + "----------------------\n" + "\n\n".join(blocks) + tail

    except Exception as e:
        return f"âŒ è®€å–è³‡æ–™å¤±æ•—ï¼Œæ­£åœ¨é‡æ–°æŠ“å–...({e})"

if __name__ == "__main__":
    if not CWA_API_KEY:
        print("âŒ è«‹å…ˆè¨­å®š CWA_API_KEY ç’°å¢ƒè®Šæ•¸ï¼")
    else:
        # æ¸¬è©¦
        print("æ¸¬è©¦æ›´æ–° CSV (é›™æª”ç­–ç•¥)...")
        update_weekly_csv()
        print("\næ¸¬è©¦è®€å– (Bot æ¨¡å¼)...")
        print(get_weekly_star_info("é¹¿æ—å¤©æ–‡å°"))